{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Codice per la valutazione di circuito ideale e rumoroso\n",
        "\n",
        "Il seguente codice si occupa di generare il circuito risultato migliore dalle valutazioni precedenti e simularlo in un contesto sia ideale che rumoroso tramite l'uso delle primitive AER messe a disposizione dalla libreria  qiskit. Per qualunque valutazione ed info più specifica non contenuta nei seguenti markdown si rimanda alla relazione."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4gWXs48swMg",
        "outputId": "36769f5b-7723-4487-8acd-fb4df8b36249"
      },
      "outputs": [],
      "source": [
        "# Installazione delle librerie necessarie\n",
        "%pip install qiskit qiskit-aer qiskit-ibm-runtime qiskit-algorithms qiskit-machine-learning\n",
        "%pip install numpy pandas scikit-learn matplotlib scipy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import delle librerie\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from qiskit import transpile\n",
        "from qiskit_aer import AerSimulator #cosi so che qui ho primitive per backend reale, non so dove gira, ma so che gira su uno reale \n",
        "                                    #e gli posso mettere rumore se voglio\n",
        "from qiskit_ibm_runtime.fake_provider import FakeVigoV2\n",
        "from qiskit.primitives import StatevectorSampler\n",
        "from qiskit.circuit.library import ZFeatureMap\n",
        "from qiskit.circuit.library import EfficientSU2\n",
        "from scipy.optimize import minimize\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Funzioni che preparano il dataset in maniera classica, e come fatto per il resto della trattazione"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Caricamento e preparazione del dataset Wine\n",
        "def load_and_prepare_wine_dataset():\n",
        "    \"\"\"Carica il dataset Wine e applica PCA a 5 componenti \"\"\"\n",
        "    \n",
        "    # Caricamento dataset Wine\n",
        "    wine = load_wine()\n",
        "    X = wine.data\n",
        "    y = wine.target\n",
        "\n",
        "    # Standardizzazione\n",
        "    scaler_standard = StandardScaler()\n",
        "    X_scaled = scaler_standard.fit_transform(X)\n",
        "\n",
        "    # Applicazione PCA a 5 componenti\n",
        "    pca = PCA(n_components=5)\n",
        "    X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "    return X_pca, y  # Restituisce y originale con 3 classi\n",
        "\n",
        "# Funzione di normalizzazione per ZFeatureMap\n",
        "def rescaler_z_feature_map(X):\n",
        "    \"\"\"Normalizza le feature per ZFeatureMap\"\"\"\n",
        "    scaler = MinMaxScaler()\n",
        "    return scaler.fit_transform(X)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Split del dataset ed istanziazione componenti del circuito"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wWHS36J5aqME",
        "outputId": "6016f481-2b7a-472a-e544-0fe0696e8ac6"
      },
      "outputs": [],
      "source": [
        "# Caricamento e preparazione dei dati\n",
        "X, y = load_and_prepare_wine_dataset()\n",
        "X_normalized = rescaler_z_feature_map(X)\n",
        "\n",
        "# Suddivisione train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_normalized, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Conversione in liste per compatibilità\n",
        "X_train_list = X_train.tolist()\n",
        "X_test_list = X_test.tolist()\n",
        "y_train_list = y_train.tolist()\n",
        "y_test_list = y_test.tolist()\n",
        "\n",
        "\n",
        "# Configurazione del circuito quantistico\n",
        "num_features = 5  \n",
        "\n",
        "\n",
        "feature_map = ZFeatureMap(feature_dimension=num_features, reps=1)\n",
        "feature_map.barrier()\n",
        "\n",
        "ansatz = EfficientSU2(num_features, reps=1)\n",
        "ansatz.barrier()\n",
        "\n",
        "# Combinazione di encoding e ansatz\n",
        "vqc_circuit = feature_map.compose(ansatz)\n",
        "vqc_circuit.measure_all()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Logica classica di gestione delle probabilità associate alla classificazione delle istanze\n",
        "\n",
        "L'unica differenza rispetto le considerazioni affrontate nel resto della trattazione consiste nella separazione del metodo \"classification_probability\" in:\n",
        "* classification_probability_ideal(data, variational_params) => gestisce il caso reale sfruttando StateVector come Sampler\n",
        "* classification_probability_noisy(data, variational_params) => gestisce il caso rumoroso utilizzando un simulatore di back-end realistico (in questo caso, FakeVigoV2, che imita un dispositivo IBM reale)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def circuit_instance(features, variational_params):\n",
        "    \"\"\"Crea un'istanza del circuito con parametri specifici\"\"\"\n",
        "    parameters = {}\n",
        "    # Assegnazione parametri della feature map\n",
        "    for i, p in enumerate(feature_map.ordered_parameters):\n",
        "        parameters[p] = features[i]\n",
        "    # Assegnazione parametri dell'ansatz\n",
        "    for i, p in enumerate(ansatz.ordered_parameters):\n",
        "        parameters[p] = variational_params[i]\n",
        "    return vqc_circuit.assign_parameters(parameters)\n",
        "\n",
        "def interpreter(bitstring):\n",
        "    \"\"\"Interpreta un bitstring come etichetta di classe \"\"\"\n",
        "    hamming_weight = sum(int(bit) for bit in bitstring)\n",
        "    return hamming_weight % 3  \n",
        "\n",
        "def label_probability(measurement_results):\n",
        "    \"\"\"Calcola le probabilità delle classi dai risultati di misura \"\"\"\n",
        "    total_shots = sum(measurement_results.values())\n",
        "    probabilities = {0: 0, 1: 0, 2: 0}  \n",
        "\n",
        "    for bitstring, counts in measurement_results.items():\n",
        "        label = interpreter(bitstring)\n",
        "        probabilities[label] += counts / total_shots\n",
        "\n",
        "    return probabilities\n",
        "\n",
        "# Funzioni di classificazione (ideale e con rumore)\n",
        "def classification_probability_ideal(data, variational_params):\n",
        "    \"\"\"Classificazione in ambiente ideale (senza rumore)\"\"\"\n",
        "    circuits = [circuit_instance(features, variational_params) for features in data]\n",
        "    sampler = StatevectorSampler()\n",
        "    results = sampler.run(circuits).result()\n",
        "    classifications = [\n",
        "        label_probability(results[i].data.meas.get_counts())\n",
        "        for i in range(len(circuits))\n",
        "    ]\n",
        "    return classifications\n",
        "\n",
        "def classification_probability_noisy(data, variational_params):\n",
        "    \"\"\"Classificazione con rumore quantistico\"\"\"\n",
        "    circuits = [circuit_instance(features, variational_params) for features in data]\n",
        "\n",
        "    fake_backend = FakeVigoV2()\n",
        "    sim = AerSimulator.from_backend(fake_backend)\n",
        "\n",
        "    transpiled_circuits = transpile(circuits, sim)\n",
        "\n",
        "    results = sim.run(transpiled_circuits).result()\n",
        "\n",
        "    classifications = []\n",
        "    for result in results.get_counts():\n",
        "        classifications.append(label_probability(result))\n",
        "\n",
        "    return classifications\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Due funzioni per gestire il caso ideale ed rumoroso\n",
        "\n",
        "Le due funzioni cost_function_ideal e cost_function_noisy calcolano la funzione di costo (loss function) da minimizzare durante l’addestramento, una chiama la funzione ideale per il calcolo delle probabilità del blocco sopra, l'altra quella rumorosa\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Funzioni di costo per l'ottimizzazione \n",
        "\n",
        "def cost_function_ideal(data, labels, variational_params):\n",
        "    \"\"\"Funzione di costo in ambiente ideale\"\"\"\n",
        "    classifications = classification_probability_ideal(data, variational_params)\n",
        "    # Converte le probabilità in formato compatibile con log_loss per 3 classi\n",
        "    y_pred_proba = [[p[0], p[1], p[2]] for p in classifications]\n",
        "    cost = log_loss(\n",
        "        y_true=labels,\n",
        "        y_pred=y_pred_proba,\n",
        "        labels=[0, 1, 2]  \n",
        "    )\n",
        "    return cost\n",
        "\n",
        "def cost_function_noisy(data, labels, variational_params):\n",
        "    \"\"\"Funzione di costo con rumore quantistico\"\"\"\n",
        "    classifications = classification_probability_noisy(data, variational_params)\n",
        "    # Converte le probabilità in formato compatibile con log_loss per 3 classi\n",
        "    y_pred_proba = [[p[0], p[1], p[2]] for p in classifications]\n",
        "    cost = log_loss(\n",
        "        y_true=labels,\n",
        "        y_pred=y_pred_proba,\n",
        "        labels=[0, 1, 2]  \n",
        "    )\n",
        "    return cost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# _Questo è un logger che stampa ogni 5 iterazioni il valore di funzione obiettivo che il modello sta valutando. Utile anche per il resto del codice per stampare i grafici delle due log-loss (decommentare assieme alle istruzioni commentate nelle righe successive per utilizzarlo)_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Logger per tracciare l'ottimizzazione\n",
        "# class OptimizationLogger:\n",
        "#     def __init__(self, use_noisy=False):\n",
        "#         self.evaluations = 1\n",
        "#         self.parameters = []\n",
        "#         self.costs = []\n",
        "#         self.use_noisy = use_noisy\n",
        "\n",
        "#     def callback(self, xk):\n",
        "#         if self.use_noisy:\n",
        "#             cost = cost_function_noisy(X_train_list, y_train_list, xk)\n",
        "#         else:\n",
        "#             cost = cost_function_ideal(X_train_list, y_train_list, xk)\n",
        "\n",
        "#         self.parameters.append(xk.copy())\n",
        "#         self.costs.append(cost)\n",
        "\n",
        "#         if self.evaluations % 5 == 0:  # Stampa ogni 5 iterazioni\n",
        "#             print(f\"Iterazione {self.evaluations}: Loss = {cost:.4f}\")\n",
        "\n",
        "#         self.evaluations += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Funzione obiettivo per l'ottimizzazione\n",
        "def objective_function_ideal(variational_params):\n",
        "    return cost_function_ideal(X_train_list, y_train_list, variational_params)\n",
        "\n",
        "def objective_function_noisy(variational_params):\n",
        "    return cost_function_noisy(X_train_list, y_train_list, variational_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Scelta degli starting point ed avvio della minimizzazione della funzione obiettivo tramite cobyla"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# OTTIMIZZAZIONE DEL MODELLO IDEALE\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"OTTIMIZZAZIONE MODELLO IDEALE\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# logger_ideal = OptimizationLogger(use_noisy=False)\n",
        "\n",
        "np.random.seed(123)  # Seed diverso per ogni modello\n",
        "initial_point_ideal = np.random.uniform(0, 2*np.pi, size=ansatz.num_parameters)\n",
        "\n",
        "print(f\"Numero di parametri da ottimizzare: {ansatz.num_parameters}\")\n",
        "print(\"Avvio ottimizzazione...\")\n",
        "\n",
        "result_ideal = minimize(\n",
        "    objective_function_ideal,\n",
        "    initial_point_ideal,\n",
        "    method=\"COBYLA\",\n",
        "    options={\"maxiter\": 3000}, \n",
        "    # callback=logger_ideal.callback\n",
        ")\n",
        "\n",
        "optimal_params_ideal = result_ideal.x\n",
        "print(f\"Ottimizzazione completata. Loss finale: {result_ideal.fun:.4f}\")\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"OTTIMIZZAZIONE MODELLO CON RUMORE\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# logger_noisy = OptimizationLogger(use_noisy=True)\n",
        "np.random.seed(456)\n",
        "initial_point_noisy = np.random.uniform(0, 2*np.pi, size=ansatz.num_parameters)\n",
        "\n",
        "print(\"Avvio ottimizzazione con rumore...\")\n",
        "result_noisy = minimize(\n",
        "    objective_function_noisy,\n",
        "    initial_point_noisy,\n",
        "    method=\"COBYLA\",\n",
        "    options={\"maxiter\": 3000},\n",
        "    # callback=logger_noisy.callback\n",
        ")\n",
        "\n",
        "optimal_params_noisy = result_noisy.x\n",
        "print(f\"Ottimizzazione completata. Loss finale: {result_noisy.fun:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Decommentare assieme al blocco precedente citato ed alle callback in quello appena sopra, per avere la stampa delle curve di convergenza della nostra funzione obiettivo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Visualizzazione delle curve di convergenza\n",
        "# plt.figure(figsize=(12, 5))\n",
        "\n",
        "# plt.subplot(1, 2, 1)\n",
        "# plt.plot(logger_ideal.costs, 'b-', label='Ideale', linewidth=2)\n",
        "# plt.xlabel('Iterazioni')\n",
        "# plt.ylabel('Loss')\n",
        "# plt.title('Convergenza Modello Ideale')\n",
        "# plt.grid(True, alpha=0.3)\n",
        "# plt.legend()\n",
        "\n",
        "# plt.subplot(1, 2, 2)\n",
        "# plt.plot(logger_noisy.costs, 'r-', label='Con Rumore', linewidth=2)\n",
        "# plt.xlabel('Iterazioni')\n",
        "# plt.ylabel('Loss')\n",
        "# plt.title('Convergenza Modello con Rumore')\n",
        "# plt.grid(True, alpha=0.3)\n",
        "# plt.legend()\n",
        "\n",
        "# plt.tight_layout()\n",
        "# plt.show()\n",
        "\n",
        "# # Confronto delle curve di convergenza\n",
        "# plt.figure(figsize=(10, 6))\n",
        "# plt.plot(logger_ideal.costs, 'b-', label='Modello Ideale', linewidth=2)\n",
        "# plt.plot(logger_noisy.costs, 'r-', label='Modello con Rumore', linewidth=2)\n",
        "# plt.xlabel('Iterazioni')\n",
        "# plt.ylabel('Loss')\n",
        "# plt.title('Confronto Convergenza: Ideale vs Con Rumore')\n",
        "# plt.grid(True, alpha=0.3)\n",
        "# plt.legend()\n",
        "# plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Funzione per valutare le prestazioni del classificatore quantistico in base al tipo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_classifier(data, labels, variational_params, use_noisy=False):\n",
        "    \"\"\"Testa il classificatore e restituisce accuratezza e predizioni\"\"\"\n",
        "    if use_noisy:\n",
        "        probabilities = classification_probability_noisy(data, variational_params)\n",
        "    else:\n",
        "        probabilities = classification_probability_ideal(data, variational_params)\n",
        "\n",
        "    predictions = [max(p, key=p.get) for p in probabilities]\n",
        "    accuracy = sum(pred == true for pred, true in zip(predictions, labels)) / len(labels)\n",
        "\n",
        "    return accuracy, predictions\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Valutazione delle accuratezze per i due modelli sfruttando i parametri ottimizzati"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# VALUTAZIONE DEI MODELLI\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"VALUTAZIONE DEI MODELLI\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Test modello ideale\n",
        "print(\"\\nModello Ideale:\")\n",
        "train_acc_ideal, train_pred_ideal = test_classifier(X_train_list, y_train_list, optimal_params_ideal, use_noisy=False)\n",
        "test_acc_ideal, test_pred_ideal = test_classifier(X_test_list, y_test_list, optimal_params_ideal, use_noisy=False)\n",
        "\n",
        "print(f\"Accuratezza Train: {train_acc_ideal:.4f}\")\n",
        "print(f\"Accuratezza Test: {test_acc_ideal:.4f}\")\n",
        "\n",
        "# Test modello con rumore\n",
        "print(\"\\nModello con Rumore:\")\n",
        "train_acc_noisy, train_pred_noisy = test_classifier(X_train_list, y_train_list, optimal_params_noisy, use_noisy=True)\n",
        "test_acc_noisy, test_pred_noisy = test_classifier(X_test_list, y_test_list, optimal_params_noisy, use_noisy=True)\n",
        "\n",
        "print(f\"Accuratezza Train: {train_acc_noisy:.4f}\")\n",
        "print(f\"Accuratezza Test: {test_acc_noisy:.4f}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Metriche varie grazie ad sk_learn e plot generali"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def calculate_metrics(y_true, y_pred, model_name):\n",
        "    \"\"\"Calcola e stampa metriche dettagliate per problema multi-classe\"\"\"\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
        "    recall = recall_score(y_true, y_pred, average='macro', zero_division=0)\n",
        "    f1 = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
        "\n",
        "    print(f\"\\n{model_name}:\")\n",
        "    print(f\"  Accuracy:  {accuracy:.4f}\")\n",
        "    print(f\"  Precision: {precision:.4f}\")\n",
        "    print(f\"  Recall:    {recall:.4f}\")\n",
        "    print(f\"  F1-Score:  {f1:.4f}\")\n",
        "\n",
        "    # Metriche per classe\n",
        "    precision_per_class = precision_score(y_true, y_pred, average=None, zero_division=0)\n",
        "    recall_per_class = recall_score(y_true, y_pred, average=None, zero_division=0)\n",
        "    f1_per_class = f1_score(y_true, y_pred, average=None, zero_division=0)\n",
        "\n",
        "    print(f\"  Metriche per classe:\")\n",
        "    for i in range(3):\n",
        "        print(f\"    Classe {i}: Prec={precision_per_class[i]:.4f}, Rec={recall_per_class[i]:.4f}, F1={f1_per_class[i]:.4f}\")\n",
        "\n",
        "    return accuracy, precision, recall, f1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calcolo metriche per entrambi i modelli\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"METRICHE DETTAGLIATE SUL TEST SET\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "metrics_ideal = calculate_metrics(y_test_list, test_pred_ideal, \"Modello Ideale\")\n",
        "metrics_noisy = calculate_metrics(y_test_list, test_pred_noisy, \"Modello con Rumore\")\n",
        "\n",
        "# Creazione tabella di confronto delle metriche\n",
        "metrics_comparison = pd.DataFrame({\n",
        "    'Modello Ideale': metrics_ideal,\n",
        "    'Modello con Rumore': metrics_noisy\n",
        "}, index=['Accuracy', 'Precision ', 'Recall', 'F1-Score '])\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"TABELLA DI CONFRONTO METRICHE\")\n",
        "print(\"=\"*50)\n",
        "print(metrics_comparison.round(4))\n",
        "\n",
        "# Visualizzazione grafica delle metriche\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Grafico a barre delle metriche\n",
        "metrics_comparison.plot(kind='bar', ax=axes[0], width=0.8)\n",
        "axes[0].set_title('Confronto Metriche di Performance ')\n",
        "axes[0].set_ylabel('Valore')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=45)\n",
        "\n",
        "# Heatmap delle metriche\n",
        "sns.heatmap(metrics_comparison, annot=True, fmt='.4f', cmap='YlOrRd', ax=axes[1])\n",
        "axes[1].set_title('Heatmap Metriche di Performance ')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Confusion Matrix -\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"CONFUSION MATRICES \")\n",
        "print(\"=\"*50)\n",
        "\n",
        "cm_ideal = confusion_matrix(y_test_list, test_pred_ideal)\n",
        "cm_noisy = confusion_matrix(y_test_list, test_pred_noisy)\n",
        "\n",
        "print(\"\\nConfusion Matrix - Modello Ideale:\")\n",
        "print(cm_ideal)\n",
        "print(\"\\nConfusion Matrix - Modello con Rumore:\")\n",
        "print(cm_noisy)\n",
        "\n",
        "# Visualizzazione Confusion Matrices\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# Etichette delle classi per le confusion matrix\n",
        "class_names = ['Classe 0', 'Classe 1', 'Classe 2']\n",
        "\n",
        "sns.heatmap(cm_ideal, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "axes[0].set_title('Confusion Matrix - Modello Ideale')\n",
        "axes[0].set_xlabel('Predetto')\n",
        "axes[0].set_ylabel('Reale')\n",
        "\n",
        "sns.heatmap(cm_noisy, annot=True, fmt='d', cmap='Reds', ax=axes[1],\n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "axes[1].set_title('Confusion Matrix - Modello con Rumore')\n",
        "axes[1].set_xlabel('Predetto')\n",
        "axes[1].set_ylabel('Reale')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Analisi dell'impatto del rumore\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"ANALISI IMPATTO DEL RUMORE\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "accuracy_drop = metrics_ideal[0] - metrics_noisy[0]\n",
        "precision_drop = metrics_ideal[1] - metrics_noisy[1]\n",
        "recall_drop = metrics_ideal[2] - metrics_noisy[2]\n",
        "f1_drop = metrics_ideal[3] - metrics_noisy[3]\n",
        "\n",
        "print(f\"Degradazione dovuta al rumore:\")\n",
        "print(f\"  Accuracy:  -{accuracy_drop:.4f} ({accuracy_drop/metrics_ideal[0]*100:.1f}%)\")\n",
        "print(f\"  Precision: -{precision_drop:.4f} ({precision_drop/metrics_ideal[1]*100:.1f}%)\")\n",
        "print(f\"  Recall:    -{recall_drop:.4f} ({recall_drop/metrics_ideal[2]*100:.1f}%)\")\n",
        "print(f\"  F1-Score:  -{f1_drop:.4f} ({f1_drop/metrics_ideal[3]*100:.1f}%)\")\n",
        "\n",
        "# Analisi distribuzione delle predizioni per classe\n",
        "print(f\"\\nDistribuzione predizioni sul test set:\")\n",
        "print(f\"  Reali:          {np.bincount(y_test_list)}\")\n",
        "print(f\"  Ideale:         {np.bincount(test_pred_ideal)}\")\n",
        "print(f\"  Con rumore:     {np.bincount(test_pred_noisy)}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"ANALISI COMPLETATA\")\n",
        "print(\"=\"*50)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "quantum_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
