{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXIaFjVTuQF8"
      },
      "source": [
        "## INTRODUZIONE AL PROGETTO ED OBIETTIVI:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLPGAOU9uWuI"
      },
      "source": [
        "In questo progetto esploriamo l'applicazione dell'informatica quantistica al problema della classificazione supervisionata, attraverso l'implementazione di un algoritmo variazionale ibrido. Utilizzando un approccio VQC (Variational Quantum Classifier), combiniamo circuiti quantistici parametrizzati con ottimizzatori classici per apprendere decision boundaries in uno spazio di feature trasformato quantisticamente.\n",
        "\n",
        "L’obiettivo principale è confrontare le performance del classificatore al variare di diverse componenti, tra cui:\n",
        "\n",
        "* Tecniche di preprocessing del dataset \n",
        "* Tipologia di ansatz quantistico \n",
        "* Scelte di encoding del dato classico \n",
        "* Ottimizzatori classici \n",
        "* Presenza o assenza di rumore quantistico\n",
        "\n",
        "Il progetto si sviluppa prevalentemente in ambiente simulato, sfruttando strumenti come Qiskit per la costruzione e l’esecuzione dei circuiti. Particolare attenzione è data anche all’interpretabilità dei risultati grazie ad un'analisi sistematica attraverso la quale intendiamo valutare i vantaggi e le criticità dei classificatori quantistici in scenari realistici, contribuendo alla comprensione della loro efficacia in confronto con i modelli classici.\n",
        "\n",
        "P.s. I markdown successivi hanno il solo scopo di dare una breve indicazione del funzionamento del singolo blocco di codice, per le motivazioni associate alle scelte progettuali e la valutazione dei risultati si prega di consultare la relazione."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " \n",
        " ## CODICE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3Xiq09-ujOv"
      },
      "source": [
        "Questa sezione assicura la disponibilità di tutti i pacchetti fondamentali\n",
        "per l'esecuzione del progetto. In particolare:\n",
        " - sklearn: per la classificazione supervisionata e la validazione dei modelli.\n",
        " - pandas: per la gestione e manipolazione dei dataset.\n",
        " - seaborn: per la visualizzazione grafica dei risultati e delle distribuzioni.\n",
        " - qiskit: framework principale per la programmazione quantistica.\n",
        " - qiskit-algorithms: moduli avanzati di Qiskit per l'uso di algoritmi ibridi.\n",
        " - pylatexenc: supporto per la visualizzazione di output in LaTeX (es. circuiti)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Be4EYojSrPbc"
      },
      "outputs": [],
      "source": [
        "# Installazione delle librerie necessarie\n",
        "!pip install sklearn\n",
        "!pip install pandas\n",
        "!pip install seaborn\n",
        "!pip install qiskit\n",
        "!pip install pylatexenc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYoj64Zsu8az"
      },
      "source": [
        "Importiamo le librerie necessarie per lo sviluppo del progetto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "zYr3_6carfS9",
        "outputId": "964dc63c-8d24-4295-dc68-459e8d5ff8da"
      },
      "outputs": [],
      "source": [
        "#IMPORT NECESSARI\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
        "                           f1_score, confusion_matrix, classification_report, log_loss)\n",
        "from scipy.optimize import minimize\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "\n",
        "# Qiskit imports\n",
        "from qiskit import QuantumCircuit\n",
        "from qiskit.circuit.library import ZFeatureMap, ZZFeatureMap, PauliFeatureMap\n",
        "from qiskit.circuit.library import RealAmplitudes, TwoLocal, EfficientSU2\n",
        "from qiskit.primitives import StatevectorSampler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KxQB0q0vHfv"
      },
      "source": [
        "Il presente blocco di codice costituisce la funzione principale (main) del nostro progetto, il flusso operativo si articola in quattro fasi principali:\n",
        "\n",
        "1. __Caricamento e preprocessing del dataset:__ viene utilizzato il dataset Wine della libreria sklearn, i cui attributi sono sottoposti a standardizzazione, selezione delle feature (NEL BLOCCO SOTTOSTANTE SONO PRESENTI COMMENTI RELATIVI AL CODICE USATO PER EFFETTUARE LE VARIE TIPOLOGIE DI FEATURES SELECTION) e normalizzazione, al fine di renderli compatibili con l'elaborazione quantistica.\n",
        "\n",
        "2. __Esecuzione degli esperimenti quantistici:__ impiegando un numero di qubit pari al numero di feature selezionate, vengono eseguiti esperimenti di classificazione quantistica mediante circuiti quantistici simulati, allo scopo di valutare le performance dei modelli quantistici su dati reali pre-elaborati.\n",
        "\n",
        "3. __Analisi dei risultati:__ infine, viene effettuata un’analisi dettagliata delle performance ottenute in termini di accuratezza e altre metriche significative.\n",
        "\n",
        "Il codice è progettato per offrire una pipeline completa e modulare, utile per esplorare l’applicabilità del Quantum Machine Learning a problemi di classificazione multiclasse reali."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "taQPNG_-sQj3"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# MAIN COMPLETO PER QUANTUM WINE CLASSIFICATION\n",
        "# =============================================================================\n",
        "\n",
        "# Impostazioni per i plot\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Funzione main che esegue tutto il pipeline di classificazione quantistica\n",
        "    \"\"\"\n",
        "\n",
        "    # =============================================================================\n",
        "    # 1. CARICAMENTO E PREPROCESSING DEL DATASET WINE CON FEATURE SELECTION\n",
        "    # =============================================================================\n",
        "\n",
        "    print(\"=\" * 80)\n",
        "    print(\"CARICAMENTO DATASET WINE E PREPROCESSING CON FEATURE SELECTION\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Caricamento dataset Wine\n",
        "    wine_data = load_wine()\n",
        "    print(\"Descrizione del dataset:\")\n",
        "    print(wine_data.DESCR[:500] + \"...\")\n",
        "\n",
        "    features = wine_data.data\n",
        "    labels = wine_data.target\n",
        "    feature_names = wine_data.feature_names\n",
        "    target_names = wine_data.target_names\n",
        "\n",
        "    print(f\"\\nShape originale features: {features.shape}\")\n",
        "    print(f\"Shape labels: {labels.shape}\")\n",
        "    print(f\"Classi: {target_names}\")\n",
        "    print(f\"Distribuzione classi: {np.bincount(labels)}\")\n",
        "\n",
        "    # Standardizzazione per le features\n",
        "    print(\"\\n\" + \"-\" * 50)\n",
        "    print(\"STANDARDIZZAZIONE E FEATURE SELECTION\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    features_scaled = scaler.fit_transform(features)\n",
        "\n",
        "\n",
        "    # Selezione delle 5 features più significative usando f_classif\n",
        "    selector = SelectKBest(score_func=f_classif, k=5)\n",
        "    features_top5 = selector.fit_transform(features_scaled, labels)\n",
        "\n",
        "    n_components = 5  # Numero fisso di features selezionate\n",
        "\n",
        "\n",
        "    # Normalizzazione delle componenti per i circuiti quantistici\n",
        "    normalizer = MinMaxScaler()\n",
        "    features_top5_normalized = normalizer.fit_transform(features_top5)\n",
        "\n",
        "    # Split train/test\n",
        "    train_features, test_features, train_labels, test_labels = train_test_split(\n",
        "        features_top5_normalized, labels, train_size=0.8, random_state=123, stratify=labels\n",
        "    )\n",
        "\n",
        "    print(f\"\\nTrain set: {len(train_features)} samples\")\n",
        "    print(f\"Test set: {len(test_features)} samples\")\n",
        "    print(f\"Train class distribution: {np.bincount(train_labels)}\")\n",
        "    print(f\"Test class distribution: {np.bincount(test_labels)}\")\n",
        "\n",
        "    # =============================================================================\n",
        "    # 2. ESECUZIONE ESPERIMENTI QUANTISTICI\n",
        "    # =============================================================================\n",
        "\n",
        "    # Numero di qubit basato sulle componenti PCA/kbest scelte\n",
        "    n_qubits = n_components\n",
        "\n",
        "    print(f\"\\n\" + \"=\" * 80)\n",
        "    print(\"AVVIO ESPERIMENTI QUANTISTICI\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"Iniziando esperimenti con {n_qubits} qubit\")\n",
        "    print(f\"Dataset: {len(train_features)} train samples, {len(test_features)} test samples\")\n",
        "    print(f\"Classi da predire: {len(target_names)} ({', '.join(target_names)})\")\n",
        "\n",
        "    # Esecuzione di tutti gli esperimenti quantistici\n",
        "    quantum_results = run_comparative_experiments(\n",
        "        train_features, train_labels, test_features, test_labels,\n",
        "        n_qubits, target_names\n",
        "    )\n",
        "\n",
        "    # =============================================================================\n",
        "    # 3. ANALISI COMPLETA DEI RISULTATI\n",
        "    # =============================================================================\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"ANALISI FINALE E CONFRONTO\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Analisi dei risultati quantistici\n",
        "    analyze_results(quantum_results, n_components)\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"ESPERIMENTI COMPLETATI CON SUCCESSO!\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    return quantum_results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Questa versione alternativa della funzione main implementa una pipeline completa per la classificazione, basata su una riduzione dimensionale del dataset Wine mediante PCA, al fine di selezionare il numero minimo di feature (e quindi di qubit) necessari a spiegare almeno il 90% della varianza, o alternativamente, cambiando una riga di codice come indicato, a selezionare solo 5 componenti per esprimere le features. L’obiettivo è ridurre lo spazio di input e, di conseguenza, il numero di qubit richiesti nel circuito quantistico, mantenendo al contempo un buon livello di informazione per la classificazione."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "    # Applicazione PCA per spiegare 90% della varianza\n",
        "    pca = PCA(n_components=0.90)  # 90% della varianza,\n",
        "     \n",
        "    #per utilizzare la tecnica di pca con 5 componenti fissate inserire\n",
        "    #pca=PCA(n_components=5)\n",
        "    \n",
        "    \n",
        "    features_pca = pca.fit_transform(features_scaled)\n",
        "\n",
        "    n_components = features_pca.shape[1]\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Abbiamo definito le varie componenti dei nostri circuiti, che verranno fatte variare per ottenere diverse combinazioni.\n",
        "\n",
        "Questa funzione ha il compito di generare una collezione dei diversi tipi di feature encoding, utilizzati per mappare dati classici nello spazio di Hilbert dei qubit. L’__input__ richiesto è il numero di qubit (n_qubits), corrispondente al numero di feature selezionate nel preprocessing dei dati. L’__output__ è un dizionario contenente tre diverse strategie di codifica implementate tramite classi della libreria Qiskit Machine Learning.\n",
        "\n",
        "I tipi di encoding scelti per i nostri confronti sono:\n",
        "\n",
        "1. ZFeatureMap: codifica le feature attraverso rotazioni attorno all'asse Z, senza entanglement tra i qubit.\n",
        "2. ZZFeatureMap: introduce interazioni di tipo ZZ tra coppie di qubit, permettendo l’introduzione di correlazioni non lineari.\n",
        "3. PauliFeatureMap: codifica più generale che combina rotazioni secondo operatori di Pauli scelti (di default X, Y, Z), con possibilità di entanglement controllato.\n",
        "\n",
        "Questi circuiti sono impiegati successivamente nella costruzione di modelli di classificazione quantistica, svolgendo un ruolo cruciale nella trasformazione dei dati classici in __input__ compatibili con la computazione quantistica."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9qFFmacsvJY"
      },
      "outputs": [],
      "source": [
        "def create_encoding_circuits(n_qubits):\n",
        "    \"\"\"Crea i diversi tipi di encoding\"\"\"\n",
        "    encodings = {}\n",
        "\n",
        "    # ZFeatureMap\n",
        "    encodings['ZFeatureMap'] = ZFeatureMap(feature_dimension=n_qubits, reps=1)\n",
        "\n",
        "    # ZZFeatureMap\n",
        "    encodings['ZZFeatureMap'] = ZZFeatureMap(feature_dimension=n_qubits, reps=1)\n",
        "\n",
        "    # PauliFeatureMap\n",
        "    encodings['PauliFeatureMap'] = PauliFeatureMap(feature_dimension=n_qubits, paulis=['XX', 'YY', 'ZZ'], reps=1)\n",
        "\n",
        "    return encodings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La funzione create_ansatz_circuits si occupa della costruzione dei diversi ansatz quantistici, ovvero dei circuiti parametrizzati utilizzati come parte variabile dell'algoritmo VQC (Variational Quantum Classifier). Un ansatz definisce la struttura del circuito quantistico su cui l’ottimizzatore classico agisce per apprendere una funzione decisionale.\n",
        "\n",
        "In particolare, la funzione accetta in input il numero di qubit (determinato dal numero di feature in input) e restituisce un dizionario contenente tre diverse tipologie di ansatz:\n",
        "\n",
        "- RealAmplitudes: un ansatz semplice, che alterna rotazioni Ry e porte CNOT, controllato dal parametro reps che definisce la profondità del circuito.\n",
        "\n",
        "- TwoLocal: un ansatz flessibile che consente di scegliere tipi di rotazioni e interazioni tra qubit; in questo caso è configurato con rotazioni Ry e accoppiamenti CX in uno schema reverse_linear.\n",
        "\n",
        "- EfficientSU2: un ansatz ispirato a strutture di reti neurali, con un buon compromesso tra espressività e profondità, spesso utilizzato in applicazioni di machine learning quantistico.\n",
        "\n",
        "Questi circuiti vengono successivamente testati e confrontati per valutarne l’efficacia nella classificazione all’interno della pipeline sperimentale."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_a9SjG8wsxWl"
      },
      "outputs": [],
      "source": [
        "def create_ansatz_circuits(n_qubits):\n",
        "    \"\"\"Crea i diversi tipi di ansatz\"\"\"\n",
        "    ansatz_dict = {}\n",
        "\n",
        "    # RealAmplitudes\n",
        "    ansatz_dict['RealAmplitudes'] = RealAmplitudes(n_qubits,entanglement='circular', reps=2)\n",
        "\n",
        "    # TwoLocal\n",
        "    ansatz_dict['TwoLocal'] = TwoLocal(n_qubits, 'ry', 'cx', 'reverse_linear', reps=2)\n",
        "\n",
        "    # EfficientSU2 (Neural Network-like)\n",
        "    ansatz_dict['EfficientSU2'] = EfficientSU2(n_qubits, reps=1)\n",
        "\n",
        "    return ansatz_dict\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La classe QuantumWineClassifier incapsula l’intero processo di codifica, costruzione e valutazione di circuiti quantistici ibridi per la classificazione multiclasse sul nostro dataset.\n",
        "# Inizializzazione del modello\n",
        "Il costruttore __init__ riceve in input due circuiti quantistici:\n",
        "\n",
        "* un feature map che codifica i dati classici in stati quantistici,\n",
        "\n",
        "* un ansatz variazionale che introduce parametri ottimizzabili nel circuito.\n",
        "\n",
        "Tali circuiti vengono concatenati mediante compose e completati da un’operazione di misura su tutti i qubit (measure_all). Vengono inoltre inizializzate una lista per la storia dei costi e una variabile per i parametri ottimali, utilizzati per ottenere i plots finali.\n",
        "\n",
        "# Metodi principali\n",
        "* circuit_instance: genera un'istanza concreta del circuito, assegnando:\n",
        "    1. i valori delle feature del singolo campione al feature map,\n",
        "    2. i parametri variazionali all’ansatz.\n",
        "\n",
        "* interpreter: decodifica una stringa di bit misurata dal circuito in una classe predetta (0, 1 o 2), usando il peso di Hamming modulo 3. Questa funzione rappresenta un meccanismo di decisione non lineare basato sull’output quantistico.\n",
        "\n",
        "* label_probability: converte un dizionario di conteggi (bitstring -> count) in una distribuzione di probabilità sulle classi, sommando le frequenze relative dei bitstring associati ad ogni classe.\n",
        "\n",
        "* classification_probability: calcola, per un insieme di dati e parametri variazionali, la probabilità di appartenenza a ciascuna classe. Per ciascun punto dati, costruisce un circuito parametrizzato, lo esegue con un simulatore a stato vettoriale (StatevectorSampler) e ne aggrega i risultati.\n",
        "\n",
        "* cost_function: valuta la qualità del modello sui dati forniti tramite la cross-entropy loss tra etichette reali e probabilità predette. Registra inoltre la storia dei valori della funzione obiettivo, utile per l’analisi dell’ottimizzazione.\n",
        "\n",
        "# Finalità\n",
        "La classe è concepita per essere utilizzata all’interno di un ciclo di addestramento variazionale (VQC), in cui i parametri dell’ansatz vengono ottimizzati per minimizzare la funzione di costo. Essa costituisce il nucleo operativo del classificatore quantistico sviluppato nel progetto, ed è parte integrante del confronto sperimentale con i metodi classici."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCs2XH_WtQfB"
      },
      "outputs": [],
      "source": [
        "class QuantumWineClassifier:\n",
        "    def __init__(self, feature_map, ansatz):\n",
        "        self.feature_map = feature_map\n",
        "        self.ansatz = ansatz\n",
        "        self.circuit = feature_map.compose(ansatz)\n",
        "        self.circuit.measure_all() #aggiungiamo delle misure per usare il nostro sampler quando valuteremo il circuito\n",
        "        self.history = []\n",
        "        self.optimal_params = None\n",
        "        \n",
        "    def circuit_instance(self, data_point, variational_params):\n",
        "        \"\"\"Crea un'istanza del circuito con parametri specifici\"\"\"\n",
        "        parameters = {}\n",
        "\n",
        "        # Parametri del feature map\n",
        "        for i, p in enumerate(self.feature_map.ordered_parameters):\n",
        "            parameters[p] = data_point[i]\n",
        "\n",
        "        # Parametri dell'ansatz\n",
        "        for i, p in enumerate(self.ansatz.ordered_parameters):\n",
        "            parameters[p] = variational_params[i]\n",
        "\n",
        "        return self.circuit.assign_parameters(parameters)\n",
        "\n",
        "    def interpreter(self, bitstring):\n",
        "        \"\"\"Interpreta la stringa di bit come classe\"\"\"\n",
        "        hamming_weight = sum(int(k) for k in list(bitstring))\n",
        "        return (hamming_weight) % 3\n",
        "\n",
        "    def label_probability(self, results):\n",
        "        \"\"\"Calcola le probabilità per ogni classe\"\"\"\n",
        "        shots = sum(results.values())\n",
        "        probabilities = {0: 0, 1: 0, 2: 0}\n",
        "\n",
        "        for bitstring, counts in results.items():\n",
        "            label = self.interpreter(bitstring)\n",
        "            probabilities[label] += counts / shots\n",
        "\n",
        "        return probabilities\n",
        "\n",
        "    def classification_probability(self, data, variational_params):\n",
        "        \"\"\"Calcola le probabilità di classificazione per un batch di dati\"\"\"\n",
        "        circuits = [self.circuit_instance(point, variational_params) for point in data]\n",
        "        sampler = StatevectorSampler() \n",
        "        #eseguo per numero di shots di default 1024, ma si può cambiare\n",
        "        results = sampler.run(circuits).result() #prende risultato in maniera asincrona con result, \n",
        "                                                 #contiene i dati associatia  a ogni possibile misuraizoni del registro classico\n",
        "                                                 #che con measure_all si chiama meas\n",
        "\n",
        "        classifications = []\n",
        "        for i, circuit in enumerate(circuits):\n",
        "            probs = self.label_probability(results[i].data.meas.get_counts()) #da quel registro classico meas, prendo i \n",
        "                                                                              #dati della result, da questo estraggo i risultati di meas\n",
        "                                                                              #da questo mi prendo i counts, cioe num di volte in cui è stato misurato lo stato base\n",
        "                                                                              #es {'110': 514, '101': 510} sul numero di shots abbiamo misurato lo stato 101 501 volte \n",
        "                                                                              #e quello 110 514\n",
        "            classifications.append(probs)\n",
        "\n",
        "        return classifications\n",
        "\n",
        "    def cost_function(self, variational_params, data, labels):\n",
        "        \"\"\"Funzione di costo (cross-entropy loss)\"\"\"\n",
        "        classifications = self.classification_probability(data, variational_params)\n",
        "        y_pred = [[p[0], p[1], p[2]] for p in classifications]\n",
        "        cost = log_loss(y_true=labels, y_pred=y_pred) #la log_loss importata è quella di sklearn che calcola la cross-entropy loss\n",
        "        self.history.append(cost)\n",
        "        \n",
        "        return cost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La funzione train si occupa della fase di addestramento del classificatore quantistico, ovvero dell’ottimizzazione dei parametri dell’ansatz al fine di minimizzare la cross-entropy.\n",
        "\n",
        "Il metodo accetta come input:\n",
        "\n",
        "- train_data e train_labels: rispettivamente i dati e le etichette del training set (già preprocessati e codificati per l’input quantistico),\n",
        "\n",
        "- optimizer: il metodo di ottimizzazione classico da utilizzare (tra quelli disponibili con scipy.optimize.minimize),\n",
        "\n",
        "- max_iter: il numero massimo di iterazioni consentite per l’ottimizzazione.\n",
        "\n",
        "L’ottimizzazione parte da un insieme casuale di parametri iniziali e utilizza una funzione obiettivo (la cost_function) che misura l’errore del modello. Tra gli ottimizzatori utilizzati vi sono:\n",
        "\n",
        "- COBYLA\n",
        "\n",
        "- L-BFGS-B\n",
        "\n",
        "- SLSQP\n",
        "\n",
        "- POWELL\n",
        "\n",
        "- NELDER-MEAD\n",
        "\n",
        "Durante l’addestramento vengono registrati il tempo impiegato, i parametri ottimali trovati, il valore finale della funzione di costo, il numero di iterazioni effettuate e un flag che indica se l’ottimizzazione è andata a buon fine. Questi risultati sono poi restituiti in forma di dizionario, utili per l’analisi comparativa tra diverse configurazioni di esperimenti.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FR6uP7njtmMD"
      },
      "outputs": [],
      "source": [
        "class QuantumWineClassifier(QuantumWineClassifier):    \n",
        "    def train(self, train_data, train_labels, optimizer='COBYLA', max_iter=5000):\n",
        "        \"\"\"Addestra il classificatore quantistico\"\"\"\n",
        "        self.history = []  #storico delle valutazioni della funzione di costo\n",
        "        initial_params = np.random.uniform(0, 2*np.pi, self.ansatz.num_parameters) #inizializza i parametri in un range da 0 a 2*pi \n",
        "\n",
        "        objective = lambda params: self.cost_function(params, train_data, train_labels)\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        if optimizer == 'COBYLA':#AGGIUNGERE EVETUALI ALTRI OTTIMIZZATORI \n",
        "            result = minimize(objective, initial_params, method='COBYLA',\n",
        "                            options={'maxiter': max_iter})\n",
        "        elif optimizer == 'L_BFGS_B':\n",
        "            result = minimize(objective, initial_params, method='L-BFGS-B',\n",
        "                            options={'maxiter': max_iter})\n",
        "        elif optimizer == 'SLSQP':\n",
        "            result = minimize(objective, initial_params, method='SLSQP',\n",
        "                            options={'maxiter': max_iter})\n",
        "        elif optimizer == 'POWELL':\n",
        "            result = minimize(objective, initial_params, method='Powell',\n",
        "                            options={'maxiter': max_iter})\n",
        "        elif optimizer == 'NELDER-MEAD':\n",
        "            result = minimize(objective, initial_params, method='Nelder-Mead',\n",
        "                            options={'maxiter': max_iter})\n",
        "        else:\n",
        "            raise ValueError(f\"Optimizer {optimizer} non supportato\")\n",
        "\n",
        "        training_time = time.time() - start_time\n",
        "\n",
        "        self.optimal_params = result.x\n",
        "        final_cost = result.fun\n",
        "\n",
        "        return {\n",
        "            'optimal_params': self.optimal_params,\n",
        "            'final_cost': final_cost,\n",
        "            'training_time': training_time,\n",
        "            'iterations': len(self.history),\n",
        "            'success': result.success\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Questi due metodi forniscono le funzionalità operative per effettuare predizioni su nuovi dati e per valutare le prestazioni del modello quantistico addestrato, una volta ottenuti i parametri ottimali dell’ansatz.\n",
        "\n",
        "__predict(data)__\n",
        "Questo metodo esegue la predizione delle classi per un insieme di dati di input (data), utilizzando i parametri ottimali ottenuti durante la fase di addestramento. In dettaglio:\n",
        "* Verifica preliminarmente che il modello sia stato addestrato (ovvero che self.optimal_params non sia None);\n",
        "\n",
        "* Chiama il metodo classification_probability, che restituisce, per ogni campione, una distribuzione di probabilità sulle tre classi;\n",
        "\n",
        "* Estrae per ciascun punto dati la classe con probabilità massima, producendo una lista di classi predette.\n",
        "\n",
        "Restituisce una tupla contenente:\n",
        "\n",
        "* le classi predette,\n",
        "* le relative distribuzioni di probabilità.\n",
        "\n",
        "__evaluate(data, labels)__\n",
        "Il metodo evaluate permette di valutare le prestazioni predittive del modello quantistico su un insieme di test. In particolare:\n",
        "\n",
        "* Esegue le predizioni richiamando predict;\n",
        "\n",
        "* Confronta le etichette predette con quelle reali (labels) tramite la metrica di accuracy, ovvero la frazione di classificazioni corrette.\n",
        "\n",
        "Il metodo restituisce:\n",
        "\n",
        "* l’accuratezza complessiva del modello sui dati di test,\n",
        "\n",
        "* l’elenco delle classi predette.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0CJZDV3tp7S"
      },
      "outputs": [],
      "source": [
        "class QuantumWineClassifier(QuantumWineClassifier):\n",
        "    def predict(self, data):\n",
        "        \"\"\"Predizione usando i parametri ottimali\"\"\"\n",
        "        if self.optimal_params is None:\n",
        "            raise ValueError(\"Modello non addestrato\")\n",
        "\n",
        "        probabilities = self.classification_probability(data, self.optimal_params)\n",
        "        predictions = [max(p, key=p.get) for p in probabilities]\n",
        "        return predictions, probabilities\n",
        "\n",
        "    def evaluate(self, data, labels):\n",
        "        \"\"\"Valuta le performance del modello\"\"\"\n",
        "        predictions, _ = self.predict(data)\n",
        "        accuracy = accuracy_score(labels, predictions)\n",
        "        return accuracy, predictions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La funzione run_comparative_experiments costituisce il cuore della fase sperimentale del progetto. Il suo obiettivo è testare sistematicamente tutte le combinazioni possibili di encoding, ansatz e ottimizzatori all’interno della pipeline di classificazione quantistica. Essa riceve in input i dati di addestramento e test, il numero di qubit (determinato inizialmente), e i nomi delle classi.\n",
        "\n",
        "All'interno della funzione:\n",
        "\n",
        "- Vengono inizializzati i diversi circuiti di encoding (feature map), gli ansatz parametrizzati e gli ottimizzatori classici scelti per la fase di training.\n",
        "\n",
        "- Per ogni combinazione encoding–ansatz–ottimizzatore, viene creato un oggetto QuantumWineClassifier e addestrato sul training set.\n",
        "\n",
        "- Dopo l'addestramento, il classificatore viene valutato sia sul training set che sul test set, e vengono calcolate le principali metriche di classificazione (accuratezza, precisione, recall e F1-score).\n",
        "\n",
        "- Per ciascun esperimento riuscito, viene generata e visualizzata una confusion matrix ed un grafico di convergenza della funzione di costo durante l’ottimizzazione.\n",
        "\n",
        "Ogni esperimento viene salvato sotto forma di dizionario, che include non solo le metriche ma anche informazioni sul numero di parametri, il tempo di training, il numero di qubit e l’esito dell’esperimento. Al termine dell’esecuzione, la funzione restituisce una lista completa dei risultati, utile per successive analisi comparative.\n",
        "\n",
        "Questo approccio esaustivo consente di valutare in modo approfondito l’impatto delle diverse scelte progettuali (encoding, ansatz, ottimizzazione) sulle prestazioni del classificatore quantistico, fornendo una base quantitativa solida per confronti con i modelli classici e per identificare le configurazioni più promettenti."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FyjyV-L7tt3u"
      },
      "outputs": [],
      "source": [
        "def run_comparative_experiments(train_features, train_labels, test_features, test_labels, n_qubits, target_names):\n",
        "    \"\"\"Esegue tutti gli esperimenti comparativi con metriche dettagliate\"\"\"\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"ESPERIMENTI COMPARATIVI VQC CON METRICHE DETTAGLIATE\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Creazione dei componenti\n",
        "    encodings = create_encoding_circuits(n_qubits)\n",
        "    ansatz_circuits = create_ansatz_circuits(n_qubits)\n",
        "    optimizers = ['COBYLA', 'L_BFGS_B', 'SLSQP','POWELL','NELDER-MEAD']  \n",
        "\n",
        "    results = []\n",
        "    experiment_count = 0\n",
        "    total_experiments = len(encodings) * len(ansatz_circuits) * len(optimizers)\n",
        "\n",
        "    print(f\"Totale esperimenti da eseguire: {total_experiments}\")\n",
        "    print(f\"Numero di qubit per esperimento: {n_qubits}\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    for enc_name, encoding in encodings.items():\n",
        "        for ans_name, ansatz in ansatz_circuits.items():\n",
        "            for optimizer in optimizers:\n",
        "                experiment_count += 1\n",
        "                print(f\"\\n{'='*20} ESPERIMENTO {experiment_count}/{total_experiments} {'='*20}\")\n",
        "                print(f\"Encoding: {enc_name}\")\n",
        "                print(f\"Ansatz: {ans_name}\")\n",
        "                print(f\"Optimizer: {optimizer}\")\n",
        "                print(f\"Parametri Ansatz: {ansatz.num_parameters}\")\n",
        "\n",
        "                # Creazione del classificatore\n",
        "                classifier = QuantumWineClassifier(encoding, ansatz)\n",
        "\n",
        "                # Addestramento\n",
        "                print(\"Addestramento in corso...\")\n",
        "                train_results = classifier.train(\n",
        "                    train_features, train_labels,\n",
        "                    optimizer=optimizer, max_iter=5000\n",
        "                )\n",
        "\n",
        "                # Valutazione\n",
        "                train_acc, train_pred = classifier.evaluate(train_features, train_labels)\n",
        "                test_acc, test_pred = classifier.evaluate(test_features, test_labels)\n",
        "\n",
        "                # Calcolo delle metriche dettagliate\n",
        "                test_precision = precision_score(test_labels, test_pred, average='weighted')\n",
        "                test_recall = recall_score(test_labels, test_pred, average='weighted')\n",
        "                test_f1 = f1_score(test_labels, test_pred, average='weighted')\n",
        "\n",
        "                print(f\"RISULTATI:\")\n",
        "                print(f\" Train Accuracy: {train_acc:.4f}\")\n",
        "                print(f\" Test Accuracy:  {test_acc:.4f}\")\n",
        "                print(f\" Test Precision: {test_precision:.4f}\")\n",
        "                print(f\" Test Recall:    {test_recall:.4f}\")\n",
        "                print(f\" Test F1-Score:  {test_f1:.4f}\")\n",
        "                print(f\" Final Cost:     {train_results['final_cost']:.4f}\")\n",
        "                print(f\" Training Time:  {train_results['training_time']:.2f}s\")\n",
        "\n",
        "                # Confusion Matrix per questo esperimento\n",
        "                experiment_title = f\"{enc_name} + {ans_name} + {optimizer}\"\n",
        "                print(f\"\\n CONFUSION MATRIX - {experiment_title}\")\n",
        "\n",
        "                cm = confusion_matrix(test_labels, test_pred)\n",
        "                plt.figure(figsize=(8, 6))\n",
        "                sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                            xticklabels=target_names, yticklabels=target_names)\n",
        "                plt.title(f'Confusion Matrix\\n{experiment_title}')\n",
        "                plt.xlabel('Predicted')\n",
        "                plt.ylabel('True')\n",
        "                plt.show()\n",
        "\n",
        "                # Grafico della convergenza\n",
        "                if len(classifier.history) > 1:\n",
        "                    plt.figure(figsize=(10, 6))\n",
        "                    plt.plot(classifier.history, 'b-', linewidth=2)\n",
        "                    plt.title(f'Training Convergence - {experiment_title}')\n",
        "                    plt.xlabel('Iteration')\n",
        "                    plt.ylabel('Cost (Log Loss)')\n",
        "                    plt.grid(True, alpha=0.3)\n",
        "                    plt.show()\n",
        "\n",
        "                # Salvataggio risultati\n",
        "                result = {\n",
        "                    'encoding': enc_name,\n",
        "                    'ansatz': ans_name,\n",
        "                    'optimizer': optimizer,\n",
        "                    'train_accuracy': train_acc,\n",
        "                    'test_accuracy': test_acc,\n",
        "                    'test_precision': test_precision,\n",
        "                    'test_recall': test_recall,\n",
        "                    'test_f1': test_f1,\n",
        "                    'final_cost': train_results['final_cost'],\n",
        "                    'training_time': train_results['training_time'],\n",
        "                    'iterations': train_results['iterations'],\n",
        "                    'success': train_results['success'],\n",
        "                    'num_parameters': ansatz.num_parameters,\n",
        "                    'num_qubits': n_qubits\n",
        "                }\n",
        "\n",
        "                results.append(result)\n",
        "\n",
        "            print(\"-\" * 80)\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La funzione analyze_results ha lo scopo di sintetizzare e visualizzare i risultati degli esperimenti quantistici, al fine di effettuare un confronto sistematico tra le diverse configurazioni testate. Essa prende in input:\n",
        "\n",
        "- l’elenco dei risultati degli esperimenti (results),\n",
        "\n",
        "- il numero di qubit utilizzati.\n",
        "\n",
        "I risultati vengono prima convertiti in un DataFrame pandas, facilitando l’analisi statistica. Vengono quindi calcolate statistiche aggregate sui soli esperimenti che hanno avuto successo (success == True), tra cui:\n",
        "\n",
        "- accuratezza media su training e test set,\n",
        "\n",
        "- precisione, richiamo e F1-score medi,\n",
        "\n",
        "- tempo medio di addestramento.\n",
        "\n",
        "Viene inoltre fornito un ranking delle 10 migliori configurazioni quantistiche in base alla test accuracy, visualizzando anche gli encoding utilizzati, l’ansatz, l’ottimizzatore e le metriche ottenute. Questo permette di identificare facilmente le combinazioni più promettenti e confrontarle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pDxc5EZot1bx"
      },
      "outputs": [],
      "source": [
        "def analyze_results(results, n_components):\n",
        "    \"\"\"Analizza e visualizza i risultati degli esperimenti con grafici avanzati\"\"\"\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"ANALISI AVANZATA DEI RISULTATI\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Conversione in DataFrame\n",
        "    df_results = pd.DataFrame(results)\n",
        "\n",
        "    # Statistiche generali\n",
        "    print(\"\\n1. STATISTICHE GENERALI\")\n",
        "    print(\"-\" * 40)\n",
        "    successful_experiments = df_results[df_results['success'] == True]\n",
        "    print(f\"Esperimenti riusciti: {len(successful_experiments)}/{len(df_results)}\")\n",
        "    print(f\"Numero di qubit utilizzati: {n_components}\")\n",
        "    print(f\"Accuracy media quantistica (train): {successful_experiments['train_accuracy'].mean():.4f} ± {successful_experiments['train_accuracy'].std():.4f}\")\n",
        "    print(f\"Accuracy media quantistica (test): {successful_experiments['test_accuracy'].mean():.4f} ± {successful_experiments['test_accuracy'].std():.4f}\")\n",
        "    print(f\"Precision media (test): {successful_experiments['test_precision'].mean():.4f} ± {successful_experiments['test_precision'].std():.4f}\")\n",
        "    print(f\"Recall media (test): {successful_experiments['test_recall'].mean():.4f} ± {successful_experiments['test_recall'].std():.4f}\")\n",
        "    print(f\"F1-Score media (test): {successful_experiments['test_f1'].mean():.4f} ± {successful_experiments['test_f1'].std():.4f}\")\n",
        "    print(f\"Tempo medio di training: {successful_experiments['training_time'].mean():.2f}s ± {successful_experiments['training_time'].std():.2f}s\")\n",
        "\n",
        "    # Top 10 configurazioni per test accuracy\n",
        "    print(\"\\n2. TOP 10 CONFIGURAZIONI (Test Accuracy)\")\n",
        "    print(\"-\" * 80)\n",
        "    top_configs = successful_experiments.nlargest(10, 'test_accuracy')\n",
        "    print(f\"{'Rank':<4} {'Encoding':<15} {'Ansatz':<15} {'Optimizer':<8} {'Test Acc':<8} {'Precision':<9} {'Recall':<7} {'F1':<7} {'Time(s)':<7}\")\n",
        "    print(\"-\" * 80)\n",
        "    for rank, (idx, row) in enumerate(top_configs.iterrows(), 1):\n",
        "        print(f\"{rank:<4} {row['encoding']:<15} {row['ansatz']:<15} {row['optimizer']:<8} \"\n",
        "              f\"{row['test_accuracy']:<8.4f} {row['test_precision']:<9.4f} {row['test_recall']:<7.4f} \"\n",
        "              f\"{row['test_f1']:<7.4f} {row['training_time']:<7.1f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wWHS36J5aqME",
        "outputId": "487316c7-eef9-4dc0-be0c-49282ba2e7b8"
      },
      "outputs": [],
      "source": [
        "# Esecuzione del main\n",
        "if __name__ == \"__main__\":\n",
        "    quantum_results, classic_metrics = main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "quantum_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
